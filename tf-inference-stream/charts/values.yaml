# Default values for charts.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# Count of stream inference workers
workersCount: 1

# Resource settings for stream inference instance
resources:
  requests:
    cpu: 19
    memory: 93604421089
  limits:
    cpu: 19
    memory: 93604421089

# Shorthands for setting both limits and requests of cpu/memory
cpu: null
memory: null


# Settings below are not intended to be modified
modelPath: ''
modelName: ''

restContainerPort: 8501
grpcContainerPort: 8500

image:
  pullPolicy: IfNotPresent
  clusterRepository: {{ NAUTA.ExperimentImage }}

experimentName: {{ NAUTA.ExperimentName }} 
podCount: 1

# Settings for CLI automatic resource configuration
cpu_fraction: 0.5
memory_fraction: 0.5
